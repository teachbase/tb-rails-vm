input {
  lumberjack {
    port => {{ elk_logstash.lumberjack_port }}
    type => "logs"
    ssl_certificate => "{{ elk_logstash.ssl_crt_dir }}/logstash.crt"
    ssl_key => "{{ elk_logstash.ssl_key_dir }}/logstash.key"
    codec => "json"
  }

  udp {
    codec => "json"
    port => {{ elk_logstash.erlang_udp_port }}
    type => "erlang"
  }
}

filter {
  if [type] == "rails" {
    geoip {
      source => "ip"
    }
  }

  if [type] == "erlang" {
    grok {
      match => { "message" =>
        "%{POSINT:task_id} %{WORD:task_status} %{WORD:task_category} %{WORD:task_type} %{NOTSPACE:file_url} %{POSINT:file_size} %{NOTSPACE:pool_name} %{POSINT:download_time} %{POSINT:process_time} %{POSINT:upload_time}"
      }
      add_field => { "source" => "fyler_server" }
    }

    grok {
      match => { "message" => "cpu %{NUMBER:cpu_value}"}
      add_field => { "source" => "fyler_pool" }
    }

    grok {
      match => { "message" => "erlyvideo_network %{WORD:network_eth} %{NUMBER:network_in} %{NUMBER:network_out}"}
      add_field => { "source" => "erlyvideo" }
    }

    mutate {
      convert => { 
        "file_size" => "integer" 
        "download_time" => "integer"
        "process_time" => "integer"
        "upload_time" => "integer"
        "cpu_value" => "float"
        "network_in" => "integer"
        "network_out" => "integer"
      }
    }
  }
}

output {
  elasticsearch { 
    host => "127.0.0.1"
    flush_size => 2000
    idle_flush_time => 5
    index => "logstash-%{+YYYY.MM.dd}"
  }
  stdout { codec => rubydebug }
}